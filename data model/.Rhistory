}
numVar<-type(data_clean, is.numeric)
catVar<-type(data_clean, is.factor)
dateVar<-type(data_clean, is.Date)
stopifnot((length(numVar)+length(catVar)+length(dateVar))==ncol(data_clean))
#TODO: Sometimes, it shows that there is no correlation between followers and change_followers
library('corrplot')
corMatrix <- cor(data_clean[, numVar])
corrplot(corMatrix, method = 'number', diag = TRUE)
#From this matrix we see that the values show no relevant linear correlation except for pRTs and
#pMentions and Followers with change_followers
corMatrix <- cor(data_clean[, numVar])
corrplot(corMatrix, method = 'number', diag = TRUE)
data_clean[, "logic_change"]<-0
data_clean$logic_change[which(data_clean$change_followers>0)]<-1
#We use stratified sampling to divide the data into training and test
library('lattice')
library('ggplot2')
library('caret')
set.seed(1234)
ind<-createDataPartition(y=data_clean$logic_change, list=FALSE, p=0.8)
train<-data_clean[ind,]
test<-data_clean[-ind,]
stopifnot(nrow(train) + nrow(test) == nrow(data_clean))
createModelFormula <- function(targetVar, xVars, includeIntercept = TRUE){
if(includeIntercept){
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ ')))
} else {
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ '), -1))
}
return(modelForm)
}
#TODO: Remove highly correlated variables?
#TODO: Introduce the groups replacing the followers
xVars<-numVar[-(which(numVar=="change_followers"))]
xVars<-xVars[-(which(numVar=="Followers"))] #We remove Followers because it was highly correlated
xVars<-c(xVars, "category")
response<-"logic_change"
modelForm <- createModelFormula(targetVar = response, xVars = xVars, includeIntercept = TRUE)
logmodel<-glm(modelForm, family=binomial(link='logit'), data=train)
summary(logmodel)
#TODO: once all the variables are set, analyze the coefficients
logpred<-predict(logmodel, test, type="response")
#Now we set a parameter to measure what we consider as a "Yes" and what we consider as "No"
threshold<-0.5
defaulted<-rep(0, length(test$logic_change))
defaulted[logpred>threshold]<-1
mean(test$logic_change)
#86% of our data corresponds to an increase of the number of followers, so there is a clear
#class imbalance
confusionMatrix(defaulted, test$logic_change)
#Our model has 86,% of probability of correctly saying whether it's going to increase or not
#so, it's not better than the default setting.
#Since there is a clear class imbalance in our data set, there is a huge difference
#between Specificity & Sensitivity
x<-sort(logpred)
plot(x, ylab='Probability', main='Logistic regression, full model')
#Since we barely have data for the lower part of the sigmoid curve, we can't draw it properly.
#Now we are going to proceed by running Stepwise selection to see if we obtain a better model
#Stepwise Selection
library(MASS)
library(stats)
simple<-glm(logic_change ~ 1,family=binomial(link='logit'), data=train)
full<-glm(modelForm,family=binomial(link='logit'), data=train)
logmodel2<-step(simple, direction="both", scope=list(upper=full, lower=simple))
summary(logmodel2)
#logmodel2$formula
#Applying stepwise selection we get that the best model is
#logic_change ~ category + pMentions + pURLs + pMedia + nTweets + isWeekend
#This makes sense as pRTs was highly correlated to pMentions
#Hashtags are simply not important
#Prediction:
logpred2<-predict(logmodel2, test, type="response")
threshold<-0.5
defaulted2<-rep(0, length(test$logic_change))
defaulted2[logpred2>threshold]<-1
confusionMatrix(defaulted2, test$logic_change)
#No changes between both models, we get the same results
#No change in the graph either
# #Lasso Regression:
# library(Matrix)
# library(foreach)
# library(glmnet)
#
# x<-model.matrix(~ nTweets + pHashtags + pMentions + pURLs + pMedia + pRTs + isWeekend + category -1, train)
# y<-as.matrix(train$logic_change)
# #We use cross-validation to choose the tuning parameter (lambda)
# cv.lasso<-cv.glmnet(x, y, alpha=1)
# best.lasso<-cv.lasso$lambda.min #we get a lambda of 0.00024
#
# xtest<-model.matrix(~ nTweets + pHashtags + pMentions + pURLs + pMedia + pRTs + isWeekend + category -1, test)
# lasso_mod<-glmnet(x, y, alpha=1, lambda=c(1,10,1))
# lasso.pre<-predict(lasso_mod, s=best.lasso, xtest)
#-------------
#Regression Model
#TODO: EXPLANATION OF THE COEFFICIENTS
#TODO: Remove highly correlated variables?
#xVars<-c(xVars, "Followers")
targetVar <-  "change_followers"
#We have to partition the data again, since now we have a different targetVar
inTrain <- createDataPartition(y = data_clean[,targetVar], list = FALSE, p = 0.8)
train <- data_clean[inTrain,]
test <- data_clean[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(data_clean))
sum(train$change_followers)/nrow(train)
sum(test$change_followers)/nrow(test)
modelForm <- createModelFormula(targetVar = targetVar, xVars = xVars, includeIntercept = TRUE)
model <- lm(modelForm, data = train)
summary(model)
#If we use Followers we have a R_squared of 0.54 for both the training and the test
#If we don't use it, we have a R_squared of 0.2234
cat('The adjusted r squared is: ', summary(model)$adj.r.squared)
#Prediction:
pred<-predict(model, test)
#The following function calculates the R_squared of the prediction
RsquaredLM<-function(pred, test, targetVar){
pred<-as.data.frame(pred)
n<-as.character(names(pred))
pred[, "actual"]<-test[, targetVar]
RSE<-sum((pred[,"actual"]-pred[, n])**2)
ymean<-mean(test[, targetVar])
Rtot<-sum((test[, targetVar]-ymean)**2)
R_squared<-1-(RSE/Rtot)
}
R_squared<-RsquaredLM(pred, test, targetVar)
cat("The value of the R squared for the test is", R_squared)
plot(model)
xVars<-xVars[-(which(numVar=="nTweets"))]
modelForm <- createModelFormula(targetVar = targetVar, xVars = xVars, includeIntercept = TRUE)
model2 <- lm(modelForm, data = train)
summary(model2)
cat('The adjusted r squared is: ', summary(model2)$adj.r.squared) #0.2236
pred2<-predict(model2, test)
R_squared2<-RsquaredLM(pred2, test, targetVar)
cat("The value of the R squared for the test is", R_squared2)
simple_lm<-lm(change_followers ~ 1, data=train)
full_lm<-lm(modelForm, data=train)
lmStep<-step(simple_lm, direction="both", scope=list(upper=full_lm, lower=simple_lm))
summary(lmStep)
cat('The adjusted r squared is: ', summary(lmStep)$adj.r.squared)
summary(lmStep)$call
anova(model, lmStep)
summary(model)$adj.r.squared
#When we did the correlation matrix we found that there is a high correlation between pRTs and
#pMentions
variables<-xVars(-(which((xVars=="pRTs")&(xVars=="pMentions"))))
#When we did the correlation matrix we found that there is a high correlation between pRTs and
#pMentions
variables<-xVars(-(which((xVars=="pRTs"))))
#When we did the correlation matrix we found that there is a high correlation between pRTs and
#pMentions
variables<-xVars[-(which((xVars=="pRTs")&(xVars=="pMentions")))]
variables
#When we did the correlation matrix we found that there is a high correlation between pRTs and
#pMentions
variables<-xVars[-(which((xVars=="pRTs")|(xVars=="pMentions")))]
xVars
xVars<-c(xVars, nTweets)
xVars<-c(xVars, 'nTweets')
xVars
variables<-xVars[-(which((xVars=="pRTs")|(xVars=="pMentions")))]
xVars<-numVar[-(which(numVar=="change_followers"))]
xVars<-xVars[-(which(numVar=="Followers"))] #We remove Followers because it was highly correlated
xVars<-c(xVars, "category")
variables<-xVars[-(which((xVars=="pRTs")|(xVars=="pMentions")))]
variables
xVars
variables<-xVars[-(which((xVars=="pRTs")|(xVars=="pMentions")))]
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ ')), "pRTs*pMentions")
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ ')), "+ ","pRTs*pMentions")
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ ')), "+ ","pRTs", "*", "pMentions")
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ '), "+ ","pRTs*pMentions"))
newModel
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ '), "+","pRTs*pMentions"))
newModel
paste0("pRTs", "*", "pMentions")
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ '), "+",paste0("pRTs", "*", "pMentions"))
)
newModel
lm.int<-lm(newModel, train)
summary(lm.int)
plot(lm.int)
pred<-predict(lm.int, test)
R_squared3<-RsquaredLM(pred3, test, targetVar)
cat("The value of the R squared for the test is", R_squared3)
pred3<-predict(lm.int, test)
R_squared3<-RsquaredLM(pred3, test, targetVar)
cat("The value of the R squared for the test is", R_squared3)
lmStep.int<-step(simple_lm, direction="both", scope=list(upper=newModel, lower=as.formula(change_followers~1)))
summary(lmStep.int)
cat('The adjusted r squared is: ', summary(lmStep)$adj.r.squared)
summary(lm.int)
summary(lmStep.int)$coefficients[,4]
summary(lm.int)$coefficients[,4]
summary(lm.int)
setwd("C:/Users/Carru/SoftwareRepositories/project571/data model")
data<-read.csv('../data collection/Data/ModelData/modelData.csv', header=T, sep=";", na.strings='Null')
#We start observing the data
index<-which(complete.cases(data)==FALSE)
#data[index, ]
#There are 3 accounts that stopped tweeting for a period of time/stopped functioning
#TODO: discuss what to do with these accounts
#Create variable isWeekend:
data[, "date"]<-as.Date(data[, "date"])
library('lubridate')
day<-wday(data[,"date"], week_start=1) #starts on Monday
data[, "isWeekend"]<-0
data$isWeekend[which(day>=6)]<-1 #Friday=5/Saturday=6
#Create variable change in number of followers
followers<- read.csv('../data collection/Data/ModelData/historicFollowers.csv',header = T,stringsAsFactors = F,sep = ';',na.strings = 'Null')
data[, "change_followers"]<-0
data$change_followers[which(data$date=="2018-02-24")]<-(data$Followers[which(data$date=="2018-02-24")]-followers$X2018.02.23)/followers$X2018.02.23
#TODO: change this when we have all the data
startday <-  data$date[1]
endday <- data$date[nrow(data)]
a1 <- data$Followers[which((data$date> (startday-1)) & (data$date< endday))]
b1 <- data$Followers[which((data$date> startday) & (data$date<(endday+1)))]
data$change_followers[data$date>startday] <- ((b1 - a1)/a1)*100
#We have made this as a percentage
#TODO: acceleration of increase in followers instead of velocity
#We create a category column
account<-read.csv('../data collection/Data/ModelData/accountsComplete.csv', header = T,stringsAsFactors = F,sep = ';',na.strings = 'Null')
data[, "category"]<-"a"
data$category[which(data$Account==account$Account)]<-account$Category
data$category<-as.factor(data$category)
#We remove the Accounts that have NAs
i<-which((data$Account=="sportbible")|(data$Account=="fabulousanimals")|(data$Account=="Earth_Pics"))
cat('The percentage of removed data is:', (length(i)/dim(data)[1])*100, '\n') #So we can delete them
data_clean<-data[-i, ]
#-----------------------------------------------------------------------------------------------
#Correlation between variables
type<-function(a, funct){
if(sum(sapply(a, funct))==0){
return(0)
}else{
return(names(which(sapply(a, funct))))
}
}
numVar<-type(data_clean, is.numeric)
catVar<-type(data_clean, is.factor)
dateVar<-type(data_clean, is.Date)
stopifnot((length(numVar)+length(catVar)+length(dateVar))==ncol(data_clean))
library('corrplot')
corMatrix <- cor(data_clean[, numVar])
corrplot(corMatrix, method = 'number', diag = TRUE)
#From this matrix we see that the values show no relevant linear correlation except for pRTs and
#pMentions and Followers with change_followers
#TODO: If you put the change_followers as percentage it shows that there is no correlation
#with the number of followers
#-----------------------------------------------------------------------------------------------
#MODELS
#-----------------------------------------------------------------------------------------------
#Logistic Regression Model
#We are going to create a variable 1-Increase 0-Decrease or stayed the same
data_clean[, "logic_change"]<-0
data_clean$logic_change[which(data_clean$change_followers>0)]<-1
#We use stratified sampling to divide the data into training and test
library('lattice')
library('ggplot2')
library('caret')
set.seed(1234)
ind<-createDataPartition(y=data_clean$logic_change, list=FALSE, p=0.8)
train<-data_clean[ind,]
test<-data_clean[-ind,]
stopifnot(nrow(train) + nrow(test) == nrow(data_clean))
createModelFormula <- function(targetVar, xVars, includeIntercept = TRUE){
if(includeIntercept){
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ ')))
} else {
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ '), -1))
}
return(modelForm)
}
#TODO: Remove highly correlated variables?
#TODO: Introduce the groups replacing the followers
xVars<-numVar[-(which(numVar=="change_followers"))]
xVars<-xVars[-(which(numVar=="Followers"))] #We remove Followers because it was highly correlated
xVars<-c(xVars, "category")
response<-"logic_change"
modelForm <- createModelFormula(targetVar = response, xVars = xVars, includeIntercept = TRUE)
logmodel<-glm(modelForm, family=binomial(link='logit'), data=train)
summary(logmodel)
#TODO: once all the variables are set, analyze the coefficients
logpred<-predict(logmodel, test, type="response")
#Now we set a parameter to measure what we consider as a "Yes" and what we consider as "No"
threshold<-0.5
defaulted<-rep(0, length(test$logic_change))
defaulted[logpred>threshold]<-1
mean(test$logic_change)
#86% of our data corresponds to an increase of the number of followers, so there is a clear
#class imbalance
confusionMatrix(defaulted, test$logic_change)
x<-sort(logpred)
plot(x, ylab='Probability', main='Logistic regression, full model')
#Since we barely have data for the lower part of the sigmoid curve, we can't draw it properly.
#Now we are going to proceed by running Stepwise selection to see if we obtain a better model
#Stepwise Selection
library(MASS)
library(stats)
simple<-glm(logic_change ~ 1,family=binomial(link='logit'), data=train)
full<-glm(modelForm,family=binomial(link='logit'), data=train)
logmodel2<-step(simple, direction="both", scope=list(upper=full, lower=simple))
summary(logmodel2)
#logmodel2$formula
#Applying stepwise selection we get that the best model is
#logic_change ~ category + pMentions + pURLs + pMedia + nTweets + isWeekend
#This makes sense as pRTs was highly correlated to pMentions
#Hashtags are simply not important
#Prediction:
logpred2<-predict(logmodel2, test, type="response")
threshold<-0.5
defaulted2<-rep(0, length(test$logic_change))
defaulted2[logpred2>threshold]<-1
confusionMatrix(defaulted2, test$logic_change)
targetVar <-  "change_followers"
#We have to partition the data again, since now we have a different targetVar
inTrain <- createDataPartition(y = data_clean[,targetVar], list = FALSE, p = 0.8)
train <- data_clean[inTrain,]
test <- data_clean[-inTrain,]
stopifnot(nrow(train) + nrow(test) == nrow(data_clean))
sum(train$change_followers)/nrow(train)
sum(test$change_followers)/nrow(test)
modelForm <- createModelFormula(targetVar = targetVar, xVars = xVars, includeIntercept = TRUE)
model <- lm(modelForm, data = train)
summary(model)
#If we use Followers we have a R_squared of 0.54 for both the training and the test
#If we don't use it, we have a R_squared of 0.2234
cat('The adjusted r squared is: ', summary(model)$adj.r.squared)
pred<-predict(model, test)
#The following function calculates the R_squared of the prediction
RsquaredLM<-function(pred, test, targetVar){
pred<-as.data.frame(pred)
n<-as.character(names(pred))
pred[, "actual"]<-test[, targetVar]
RSE<-sum((pred[,"actual"]-pred[, n])**2)
ymean<-mean(test[, targetVar])
Rtot<-sum((test[, targetVar]-ymean)**2)
R_squared<-1-(RSE/Rtot)
}
R_squared<-RsquaredLM(pred, test, targetVar)
cat("The value of the R squared for the test is", R_squared)
simple_lm<-lm(change_followers ~ 1, data=train)
full_lm<-lm(modelForm, data=train)
lmStep<-step(simple_lm, direction="both", scope=list(upper=full_lm, lower=simple_lm))
summary(lmStep)
cat('The adjusted r squared is: ', summary(lmStep)$adj.r.squared) #0.2236
anova(model, lmStep)
summary(model)$adj.r.squared
variables<-xVars[-(which((xVars=="pRTs")|(xVars=="pMentions")))]
newModel<-as.formula(paste(targetVar, "~", paste(variables, collapse = '+ '), "+","pRTs*pMentions"))
lm.int<-lm(newModel, train)
summary(lm.int)
cat('The adjusted r squared is: ', summary(lm.int)$adj.r.squared)
pred3<-predict(lm.int, test)
R_squared3<-RsquaredLM(pred3, test, targetVar)
cat("The value of the R squared for the test is", R_squared3)
summary(lm.int)
newModel
#TODO: ALL OF THIS IS DONE BY HAND, DO A FUNCTION
#I use an alpha of 0.5
lmReduced.int<-lm(change_followers~nTweets + pURLs+ pMedia+ category+pRTs*pMentions, data=train)
summary(lmReduced.int)
pred4<-predict(lmReduced.int, test)
R_squared4<-RsquaredLM(pred4, test, targetVar)
cat("The value of the R squared for the test is", R_squared4)
#TODO: anova comparison of all the regression models?
anova(model, lmStep, lm.int, lmReduced.int)
anova(model, lm.int)
poly(nTweets, pRTs, 2, raw=TRUE)
xVars
pol.reg<-lm(change_followers~poly(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, category, 2, raw=TRUE), data=train)
pol.reg<-lm(change_followers~polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, category, 2, raw=TRUE), data=train)
pol.reg<-lm(change_followers~polym(xVars, 2, raw=TRUE), data=train)
pol.reg<-lm(change_followers~polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, category, degree=2, raw=TRUE), data=train)
sum(complete.cases(train))
pol.reg<-lm(change_followers~polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, category, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers~polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, category, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, degree=2, raw=TRUE), data=train)
summary(pol.reg)
pol.reg<-lm(change_followers ~ polym(nTweets, pHastags, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, degree=2, raw=TRUE), data=train)
sumary(pol.reg)
summary(pol.reg)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, degree=2, raw=FALSE), data=train)
summary(pol.reg)
pol.reg<-lm(change_followers ~ nTweets+pHashtags+nTweets*pHashtags +poly(nTweets, 2)+ poly(pHashtags, 2), train)
summary(pol.reg)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, degree=2, raw=TRUE), data=train)
summary(pol.reg)
xVars
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags,pMentions degree=2, raw=TRUE), data=train)
summary(pol.reg)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions, degree=2, raw=TRUE), data=train)
summary(pol.reg)
xVars
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions, pURLs, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions, pURLs, pMedia, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, category,degree=2, raw=TRUE), data=train)
pol.reg<-lm(change_followers ~ category +polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=2, raw=TRUE), data=train)
summary(pol.reg)
pol.reg2<-lm(change_followers ~ category +polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=2, raw=TRUE), data=train)
summary(pol.reg2)
cat('The adjusted r squared is: ', summary(pol.reg2)$adj.r.squared)
pol.reg3<-lm(change_followers ~ category +polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=3, raw=TRUE), data=train)
summary(pol.reg3)
cat('The adjusted r squared is: ', summary(pol.reg3)$adj.r.squared)
pol.reg4<-lm(change_followers ~ category +polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=4, raw=TRUE), data=train)
summary(pol.reg4)
cat('The adjusted r squared is: ', summary(pol.reg4)$adj.r.squared)
pol.reg5<-lm(change_followers ~ category +polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=4, raw=TRUE), data=train)
summary(pol.reg5)
cat('The adjusted r squared is: ', summary(pol.reg5)$adj.r.squared)
anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5)
anova(pol.reg2, pol.reg3, pol.reg4, pol.reg5)
#It is unusual to take values higher than 3/4 because the curve can become over flexible
#TODO: look for the full explanation
anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5)
labels(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))
names(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))
names(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))$.Pr(>F)
names(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))$Pr(>F)
names(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))[5]
(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))[5]
(anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5))[6]
anova(model, lm.int, pol.reg2, pol.reg3, pol.reg4, pol.reg5)
pol.reg5<-lm(change_followers ~ category +polym(nTweets, pHashtags, pMentions, pURLs, pMedia, pRTs, isWeekend, degree=5, raw=TRUE), data=train)
summary(pol.reg5)
cat('The adjusted r squared is: ', summary(pol.reg5)$adj.r.squared)
anova(model, pol.reg2, pol.reg3, pol.reg4, pol.reg5)
summary(pol.reg4)$adj.r.squared
summary(pol.reg3)$adj.r.squared
anova(pol.reg3, pol.reg4)
summary(pol.reg4)
str(summary(pol.reg4))
head(summary(pol.reg4))
a<-summary(pol.reg4)
View(a)
names(summary(pol.reg2))
summary(pol.reg2)
summary(pol.reg2)
head(summary(pol.reg2)$coefficients[1])
summary(pol.reg2)$coefficients[1]
head(summary(pol.reg2)$coefficients[,1])
head(summary(pol.reg2)$coefficients[,4])
#We compare it with the "basic" model to choose the order of the polynomial
#It is unusual to take values higher than 3/4 because the curve can become over flexible. So,
#we choose order 4
#TODO: look for the full explanation
p<-summary(pol.reg2)$coefficients[,4]
head(p)
str(p)
head(names(p))
ind<-p<alpha
p[1]
str(p)
ind<-which(p<alpha)
p[1]<alpha
p[[1]]<alpha
alpha<-0.05
ind<-p<alpha
sum(ind)
length(p)
candidates<-p[p<alpha]
candidates[1]
p[1]
candidates[2]
candidates[5]
candidates[4]
candidates[3]
candidates[5]
candidates[6]
candidates[7]
candidates[8]
candidates[9]
candidates[10]
candidates[11]
candidates[12]
candidates[13]
candidates[14]
candidates[15]
candidates[16]
candidates[17]
candidates[18]
candidates[19]
candidates[20]
candidates[21]
candidates[22]
pol.reg.pruned<-lm(change_followers ~ category + poly(pURLs, pMedia, degree=2, raw=TRUE) +
nTweets*pMentions+ pHashtags + pHashtags:pMentions + nTweets:pURLs+
pHashtags:pURLs+ pURLs:pMentions + pHashtags:pMedia +
pMedia:pMentions + pURLs:pRTs + pMedia:pRTs + pRTs, train)
summary(pol.reg.pruned)$adj.r.squared
summary(pol.reg2)$adj.r.squared
summary(pol.reg4)$adj.r.squared
p<-summary(pol.reg4)$coefficients[,4]
candidates<-p[p<alpha]
pol.reg<-lm(change_followers ~ category + poly(pURLs, pMedia, degree=2, raw=TRUE) +
nTweets*pMentions+ pHashtags*pMentions + nTweets:pURLs+
pHashtags:pURLs+ pURLs:pMentions + pHashtags:pMedia +
pMedia:pMentions + pURLs:pRTs + pMedia*pRTs, train)
summary(pol.reg)
pol.reg.pruned<-lm(change_followers ~ category + poly(pURLs, pMedia, degree=2, raw=TRUE) +
nTweets*pMentions+ pHashtags + pHashtags:pMentions + nTweets:pURLs+
pHashtags:pURLs+ pURLs:pMentions + pHashtags:pMedia +
pMedia:pMentions + pURLs:pRTs + pMedia:pRTs + pRTs, train)
summary(pol.reg.pruned)
candidates[5]
candidates[4]
candidates[3]
