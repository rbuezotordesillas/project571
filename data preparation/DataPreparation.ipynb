{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "#from datetime import datetime,timedelta\n",
    "#from pytz import timezone\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(path):\n",
    "    '''returns datarfame from json file'''\n",
    "    with open(path,'r') as fp: #load historic tweets\n",
    "        tweets_json = json.load(fp)\n",
    "    return pd.read_json(tweets_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataFrame(df,path):\n",
    "    '''save DataFerame in csv format'''\n",
    "    df.to_csv(path,sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(l):\n",
    "    if not(type(l)==list):\n",
    "        return 'Null,Null,Null,Null,Null,Null'\n",
    "    nTweets = len(l)\n",
    "    if nTweets == 0:\n",
    "        return '0,0,0,0,0,0'\n",
    "    nHashtags = 0\n",
    "    nMentions = 0\n",
    "    nURLs = 0\n",
    "    nMedia = 0\n",
    "    nRT = 0\n",
    "    for t in l:\n",
    "        if bool (t['entities']['hashtags']) :\n",
    "            nHashtags += 1\n",
    "        if bool (t['entities']['user_mentions']) :\n",
    "            nMentions += 1\n",
    "        if bool (t['entities']['urls']) :\n",
    "            nURLs += 1\n",
    "        if 'media' in t['entities']:\n",
    "            nMedia += 1\n",
    "        if 'retweeted_status' in t:\n",
    "            nRT += 1\n",
    "    r = [nTweets,nHashtags/nTweets,nMentions/nTweets,nURLs/nTweets,nMedia/nTweets,nRT/nTweets]\n",
    "    r = [round(x,4) for x in r]\n",
    "    return ','.join(str(e) for e in r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModelData(json_df):\n",
    "    df = pd.DataFrame() #aux DataFrame\n",
    "    date = json_df.columns[0]\n",
    "    df['data'] = json_df[date].apply(getData) #Collect all attributes into a single column\n",
    "    df = df.data.str.split(',',expand=True) #split into different columns\n",
    "    df.columns = ['nTweets','pHashtags', 'pMentions', 'pURLs', 'pMedia', 'pRTs']\n",
    "    json_df = json_df.join(df) #join to main DataFrame\n",
    "    json_df['date'] = date #add date\n",
    "    json_df = json_df.drop(columns = [date], axis =1) #drop tweet list\n",
    "    return json_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2018-03-13     Account\n",
      "43       None  sportbible\n",
      "Holi\n",
      "   2018-03-14     Account\n",
      "43       None  sportbible\n",
      "Holi\n",
      "    2018-03-15          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-16          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-17          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-18          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-19          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-20          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-21          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-22          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-23          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-24          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-25          Account\n",
      "43        None       sportbible\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-26          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-27          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-28          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-29          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-30          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-03-31          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-04-01          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n",
      "    2018-04-02          Account\n",
      "49        None       Earth_Pics\n",
      "146       None  fabulousanimals\n",
      "Holi\n"
     ]
    }
   ],
   "source": [
    "load_from = '../data collection/Data/ModelData/Tweets'\n",
    "save_to = '../data collection/Data/ModelData/byDate/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "for p in pathlist:\n",
    "    tweets = loadJson(p)\n",
    "    date = p.name[13:-5]\n",
    "    if tweets[date].isnull().any():\n",
    "        print(tweets[tweets[date].isnull()])\n",
    "    modelData = generateModelData(tweets)\n",
    "    saveDataFrame(modelData,path=save_to+p.name[:-5]+'.csv')\n",
    "    print('Holi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loadJson('../data collection/Data/ModelData/Tweets/todaysTweets_2018-03-16.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['2018-03-16'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account</th>\n",
       "      <th>nTweets</th>\n",
       "      <th>pHashtags</th>\n",
       "      <th>pMentions</th>\n",
       "      <th>pURLs</th>\n",
       "      <th>pMedia</th>\n",
       "      <th>pRTs</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonappetit</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NatGeoFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TwitterFood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fooddotcom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newfoodeconomy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Account nTweets pHashtags pMentions pURLs pMedia pRTs        date\n",
       "0      bonappetit      24       0.0    0.0417  0.75   0.25  0.0  2018-02-24\n",
       "1      NatGeoFood       0         0         0     0      0    0  2018-02-24\n",
       "2     TwitterFood       0         0         0     0      0    0  2018-02-24\n",
       "3      Fooddotcom       0         0         0     0      0    0  2018-02-24\n",
       "4  newfoodeconomy       5       0.0       0.0   1.0    0.2  0.0  2018-02-24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join collected tweet data with account data\n",
    "accounts_df = pd.read_csv('../data collection/Data/accounts.csv',sep=\";\")\n",
    "test = test.merge(accounts_df,how='inner',on='Account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data collection/Data/todaysFollowers_2018-02-24.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-db077a13cd4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfollowers_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data collection/Data/todaysFollowers_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../data collection/Data/todaysFollowers_2018-02-24.csv' does not exist"
     ]
    }
   ],
   "source": [
    "followers_df = pd.read_csv('../data collection/Data/todaysFollowers_'+date+'.csv',sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account</th>\n",
       "      <th>nTweets</th>\n",
       "      <th>pHashtags</th>\n",
       "      <th>pMentions</th>\n",
       "      <th>pURLs</th>\n",
       "      <th>pMedia</th>\n",
       "      <th>pRTs</th>\n",
       "      <th>date</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>BigCheds</td>\n",
       "      <td>54</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Trading&amp;Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>DanielsTrading</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Trading&amp;Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>canuck2usa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Trading&amp;Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>BourseetTrading</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Trading&amp;Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tradingview</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Trading&amp;Finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Account nTweets pHashtags pMentions   pURLs pMedia    pRTs  \\\n",
       "179         BigCheds      54    0.4444    0.1667  0.3148    0.5  0.1667   \n",
       "180   DanielsTrading       0         0         0       0      0       0   \n",
       "181       canuck2usa       3       0.0       0.0  0.3333    0.0     0.0   \n",
       "182  BourseetTrading      60      0.95    0.9833     0.7    0.0    0.85   \n",
       "183      tradingview       6       0.0       0.0     1.0    0.0     0.0   \n",
       "\n",
       "           date         Category  \n",
       "179  2018-02-24  Trading&Finance  \n",
       "180  2018-02-24  Trading&Finance  \n",
       "181  2018-02-24  Trading&Finance  \n",
       "182  2018-02-24  Trading&Finance  \n",
       "183  2018-02-24  Trading&Finance  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = True\n",
    "not a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sportbible'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_df['Account'][43]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
